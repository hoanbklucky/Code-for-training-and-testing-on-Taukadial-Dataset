{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r'C:\\Users\\ngoth\\OneDrive - flsouthern.edu\\Research\\AI4AD_Speech\\TAUKADIAL\\TAUKADIAL-24-test\\TAUKADIAL-24\\test'\n",
    "filename = os.path.join(dir, 'testgroundtruth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tkdname</th>\n",
       "      <th>mmse</th>\n",
       "      <th>dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taukdial-001-1.wav</td>\n",
       "      <td>27</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>taukdial-001-2.wav</td>\n",
       "      <td>27</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>taukdial-001-3.wav</td>\n",
       "      <td>27</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taukdial-010-1.wav</td>\n",
       "      <td>27</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taukdial-010-2.wav</td>\n",
       "      <td>27</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>taukdial-010-3.wav</td>\n",
       "      <td>27</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>taukdial-012-1.wav</td>\n",
       "      <td>29</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>taukdial-012-2.wav</td>\n",
       "      <td>29</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>taukdial-012-3.wav</td>\n",
       "      <td>29</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taukdial-013-1.wav</td>\n",
       "      <td>28</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tkdname  mmse   dx\n",
       "0  taukdial-001-1.wav    27   NC\n",
       "1  taukdial-001-2.wav    27   NC\n",
       "2  taukdial-001-3.wav    27   NC\n",
       "3  taukdial-010-1.wav    27  MCI\n",
       "4  taukdial-010-2.wav    27  MCI\n",
       "5  taukdial-010-3.wav    27  MCI\n",
       "6  taukdial-012-1.wav    29   NC\n",
       "7  taukdial-012-2.wav    29   NC\n",
       "8  taukdial-012-3.wav    29   NC\n",
       "9  taukdial-013-1.wav    28  MCI"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(filename, sep=';')\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tkdname</th>\n",
       "      <th>dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taukdial-001-1.wav</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>taukdial-001-2.wav</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>taukdial-001-3.wav</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taukdial-010-1.wav</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taukdial-010-2.wav</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>taukdial-010-3.wav</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tkdname   dx\n",
       "0  taukdial-001-1.wav   NC\n",
       "1  taukdial-001-2.wav   NC\n",
       "2  taukdial-001-3.wav   NC\n",
       "3  taukdial-010-1.wav  MCI\n",
       "4  taukdial-010-2.wav  MCI\n",
       "5  taukdial-010-3.wav  MCI"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = test_df.loc[0:5, [\"tkdname\", \"dx\"]]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play an audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ngoth\\miniconda3\\envs\\pyml-book\\Lib\\site-packages\\gradio\\processing_utils.py:738: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate: 48000\n",
      "array: [-0.01504517 -0.01509094 -0.01547241 ... -0.0065918  -0.00686646\n",
      " -0.00715637]\n",
      "length: 858913\n",
      "new array: [-0.00988969 -0.0171406  -0.01512437 ... -0.00557384 -0.00704113\n",
      "  0.        ]\n",
      "new length: 286305\n",
      "new sampling rate: 16000\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import scipy.io.wavfile as wavfile\n",
    "#from scipy.signal import resample\n",
    "from librosa import  resample, load\n",
    "\n",
    "\"\"\" def resample_audio(array, sampling_rate):\n",
    "    num_samples = int(len(array) * float(16000) / sampling_rate)\n",
    "    array = resample(array, num_samples)\n",
    "    sampling_rate = 16000\n",
    "    return array, sampling_rate \"\"\"\n",
    "\n",
    "def generate_audio():\n",
    "    example = test_df.loc[0, [\"tkdname\", \"dx\"]].to_dict()\n",
    "    array, sampling_rate = load(os.path.join(dir, example[\"tkdname\"]), sr=None)\n",
    "    print('sampling rate:', sampling_rate)\n",
    "    print('array:', array)\n",
    "    print('length:', len(array))\n",
    "    if sampling_rate != 16000:\n",
    "        array = resample(array, orig_sr=sampling_rate, target_sr=16000)\n",
    "        sampling_rate = 16000\n",
    "        print('new array:', array)\n",
    "        print('new length:', len(array))  \n",
    "        print('new sampling rate:', sampling_rate)\n",
    "      \n",
    "    return (\n",
    "        sampling_rate,\n",
    "        array,\n",
    "    ), example[\"dx\"]\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Column():\n",
    "        for _ in range(1):\n",
    "            audio, label = generate_audio()\n",
    "            output = gr.Audio(audio, label=label)\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ntu-spml/distilhubert\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_id, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate = feature_extractor.sampling_rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'NC': 0, 'MCI': 1}\n",
      "id2label: {0: 'NC', 1: 'MCI'}\n"
     ]
    }
   ],
   "source": [
    "label2id = {label: i for i, label in enumerate(test_df[\"dx\"].unique())}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "print(f'label2id: {label2id}')\n",
    "print(f'id2label: {id2label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (array-like): The input data.\n",
    "            labels (array-like): The labels corresponding to the data.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        array, sampling_rate =  load(os.path.join(dir, self.data[idx]), sr=None)\n",
    "        #print('sampling rate:', sampling_rate)\n",
    "        if sampling_rate != 16000:\n",
    "            array = resample(array, orig_sr=sampling_rate, target_sr=16000)\n",
    "            sampling_rate = 16000\n",
    "        inputs = feature_extractor(\n",
    "            array,\n",
    "            sampling_rate=sampling_rate,\n",
    "            max_length=int(feature_extractor.sampling_rate * max_duration),\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        label = label2id[self.labels[idx]]\n",
    "        return inputs, label\n",
    "\n",
    "# Example usage:\n",
    "test_data = test_df[\"tkdname\"] # Load your data here\n",
    "test_labels = test_df[\"dx\"] # Load your labels here\n",
    "test_dataset = AudioDataset(test_data, test_labels)\n",
    "test_dataset_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.3493408e-03, -9.5359515e-04,  9.4110658e-03, ...,\n",
       "       -6.1296177e-01, -9.6241987e-01, -1.5171903e+00], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[3][0]['input_values'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480000\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[2][0]['input_values'][0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_values': [tensor([[ 0.1522,  0.2561,  0.2258,  ...,  0.2291,  0.2204,  0.2213],\n",
      "        [ 0.0075,  0.0018, -0.0039,  ..., -0.2242, -0.2040, -0.2300],\n",
      "        [-0.0009, -0.0009, -0.0009,  ...,  0.0267,  0.0283,  0.0289],\n",
      "        [-0.2964, -0.5448, -0.5291,  ...,  0.2162,  0.2156,  0.2202]])], 'attention_mask': [tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)]}, tensor([1, 1, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(test_dataset_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_values: [tensor([[ 0.1693,  0.2805,  0.2403,  ...,  0.4438,  0.4428,  0.4404],\n",
      "        [-0.0103, -0.0184, -0.0146,  ...,  1.0376,  0.3517, -0.3808],\n",
      "        [-0.0501, -0.0784, -0.0620,  ...,  1.0306,  1.0188,  1.0133],\n",
      "        [-0.0189, -0.0357, -0.0239,  ..., -0.1718, -0.1677, -0.1545]])]\n",
      "attention_mask: [tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)]\n",
      "labels: tensor([0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "data, labels = next(iter(test_dataset_dataloader))\n",
    "#data = sample_batch[0]\n",
    "#labels = sample_batch[1]\n",
    "for k, v in data.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "print(f\"labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -1.34e-09, Variance: 0.596\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample = test_dataset[0]\n",
    "print(f'Mean: {np.mean(sample[0][\"input_values\"]):.3}, Variance: {np.var(sample[0][\"input_values\"]):.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model for audio classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(id2label)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at ntu-spml/distilhubert and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=num_labels,\n",
    "    label2id = label2id,\n",
    "    id2label = id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f912d65bdb24780b5e7dc147d81a7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to check GPU memory usage\n",
    "def print_gpu_memory():\n",
    "    print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"Cached memory: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 73.25 MB\n",
      "Cached memory: 158.00 MB\n"
     ]
    }
   ],
   "source": [
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 14.65 MB\n",
      "Cached memory: 20.00 MB\n"
     ]
    }
   ],
   "source": [
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngoth\\AppData\\Local\\Temp\\ipykernel_16128\\2067073061.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./trained models/mci model 85 acc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/120 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.5197, -0.9007, -0.7948,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   2%|▏         | 2/120 [00:00<00:23,  5.06batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(4.5348, device='cuda:0'), logits=tensor([[-2.2527,  2.2713]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.2581, 0.4063, 0.3297,  ..., 0.0000, 0.0000, 0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(4.8067, device='cuda:0'), logits=tensor([[-2.3900,  2.4084]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.2840, -0.4457, -0.3289,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   3%|▎         | 4/120 [00:00<00:16,  7.19batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(2.5620, device='cuda:0'), logits=tensor([[-1.2595,  1.2222]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 2.3493e-03, -9.5360e-04,  9.4111e-03,  ..., -6.1296e-01,\n",
      "         -9.6242e-01, -1.5172e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0636, device='cuda:0'), logits=tensor([[-1.4001,  1.3231]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0134, 0.0014, 0.0087,  ..., 0.0000, 0.0000, 0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▌         | 6/120 [00:00<00:13,  8.36batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.9810, device='cuda:0'), logits=tensor([[ 0.2034, -0.3077]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0008, 0.0011, 0.0018,  ..., 0.0000, 0.0000, 0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0074, device='cuda:0'), logits=tensor([[-2.4595,  2.4464]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.4676,  0.4982,  0.2711,  ..., -0.4285, -0.7020, -0.7811]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   7%|▋         | 8/120 [00:01<00:12,  8.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(7.2363, device='cuda:0'), logits=tensor([[-3.5751,  3.6605]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0388, -0.0515,  0.0505,  ..., -1.4341, -0.9831, -0.0319]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.1366, device='cuda:0'), logits=tensor([[-3.5362,  3.5996]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0040,  0.0035,  0.0020,  ..., -0.1696, -0.2557, -0.4432]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 10/120 [00:01<00:12,  8.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(6.9013, device='cuda:0'), logits=tensor([[-3.4162,  3.4841]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-1.8870, -0.1808,  0.2800,  ...,  3.8121,  3.4188,  2.3286]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0043, device='cuda:0'), logits=tensor([[-2.7004,  2.7429]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.2116, 0.2749, 0.2763,  ..., 0.0053, 0.0053, 0.0053]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  10%|█         | 12/120 [00:01<00:11,  9.04batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0024, device='cuda:0'), logits=tensor([[-2.9990,  3.0383]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0038, -0.0011,  0.0037,  ...,  0.0039,  0.0039,  0.0039]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0023, device='cuda:0'), logits=tensor([[-3.0057,  3.0594]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0075,  0.0018, -0.0039,  ..., -0.2242, -0.2040, -0.2300]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  12%|█▎        | 15/120 [00:01<00:11,  9.39batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0072, device='cuda:0'), logits=tensor([[-2.4653,  2.4691]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0920, -0.0847, -0.0674,  ..., -0.3422, -0.3277, -0.3151]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.2571, device='cuda:0'), logits=tensor([[-0.6440,  0.5832]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0554, -0.1073, -0.1523,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.4624, device='cuda:0'), logits=tensor([[-0.2979,  0.2333]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  13%|█▎        | 16/120 [00:01<00:11,  9.38batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[0.0112, 0.0101, 0.0097,  ..., 0.0030, 0.0030, 0.0032]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.0262, device='cuda:0'), logits=tensor([[-3.4811,  3.5442]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0590, 0.0674, 0.0753,  ..., 0.0000, 0.0000, 0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(6.9648, device='cuda:0'), logits=tensor([[-3.4502,  3.5137]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  15%|█▌        | 18/120 [00:02<00:10,  9.54batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[0.0051, 0.0051, 0.0041,  ..., 0.1017, 0.1064, 0.1002]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(6.9418, device='cuda:0'), logits=tensor([[-3.4463,  3.4945]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0128, -0.0171, -0.0057,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  17%|█▋        | 20/120 [00:02<00:11,  8.55batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0114, device='cuda:0'), logits=tensor([[-2.2450,  2.2265]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0030,  0.0072,  0.0028,  ..., -0.0727, -0.0515, -0.0628]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0057, device='cuda:0'), logits=tensor([[-2.5915,  2.5716]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0573,  0.1120,  0.1215,  ..., -0.0208, -0.0256, -0.0299]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  18%|█▊        | 22/120 [00:02<00:12,  8.07batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0010, device='cuda:0'), logits=tensor([[-3.4388,  3.4655]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.1042, -0.1764, -0.1830,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.2663, device='cuda:0'), logits=tensor([[ 3.5663, -3.6993]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0184, -0.0739, -0.0892,  ...,  2.1638,  0.7655, -0.8911]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  20%|██        | 24/120 [00:02<00:11,  8.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(7.1452, device='cuda:0'), logits=tensor([[ 3.5011, -3.6433]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-8.6322e-05,  6.4229e-05, -2.9852e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.3137, device='cuda:0'), logits=tensor([[ 3.5887, -3.7243]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  21%|██        | 25/120 [00:03<00:13,  6.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.0070, -0.0121, -0.0094,  ..., -0.0043, -0.0029, -0.0019]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(1.3343, device='cuda:0'), logits=tensor([[ 0.4726, -0.5560]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0064,  0.0120,  0.0116,  ..., -0.0232, -0.0268, -0.0292]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  22%|██▏       | 26/120 [00:03<00:14,  6.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(1.3595, device='cuda:0'), logits=tensor([[ 0.4921, -0.5706]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0075, 0.0107, 0.0094,  ..., 0.0110, 0.0112, 0.0109]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.8246, device='cuda:0'), logits=tensor([[ 0.1002, -0.1475]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  23%|██▎       | 28/120 [00:03<00:13,  6.63batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.5472, -0.9050, -0.7822,  ..., -0.9131, -0.8840, -0.9052]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0780, device='cuda:0'), logits=tensor([[-1.2703,  1.2412]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.4599, -0.7593, -0.6719,  ...,  1.1861,  1.2354,  1.2053]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  25%|██▌       | 30/120 [00:03<00:12,  7.46batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(1.1282, device='cuda:0'), logits=tensor([[ 0.3376, -0.3996]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0319, -0.0479, -0.0511,  ...,  1.5160, -0.2678,  0.2455]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(1.4792, device='cuda:0'), logits=tensor([[ 0.5855, -0.6351]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.2783, -0.4300, -0.5591,  ..., -0.0932, -0.0829, -0.0703]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  27%|██▋       | 32/120 [00:04<00:10,  8.18batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(1.1871, device='cuda:0'), logits=tensor([[ 0.3318, -0.4914]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.1642, -0.1843, -0.2143,  ...,  0.0188,  0.0318,  0.0112]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0032, device='cuda:0'), logits=tensor([[-2.8732,  2.8793]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.6937, -0.0359,  1.1071,  ...,  0.8240,  0.6138,  0.4061]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  28%|██▊       | 33/120 [00:04<00:10,  8.53batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0112, device='cuda:0'), logits=tensor([[-2.2790,  2.2090]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0224, 0.0436, 0.0333,  ..., 0.1255, 0.1146, 0.0922]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.2007, device='cuda:0'), logits=tensor([[ 3.5279, -3.6721]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  29%|██▉       | 35/120 [00:04<00:11,  7.36batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.0189, -0.0357, -0.0239,  ..., -0.1718, -0.1677, -0.1545]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.2135, device='cuda:0'), logits=tensor([[ 3.5323, -3.6804]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0065,  0.0331,  0.0379,  ..., -0.1585, -0.1966, -0.2317]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  30%|███       | 36/120 [00:04<00:11,  7.19batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(6.9835, device='cuda:0'), logits=tensor([[ 3.4252, -3.5574]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0852, -0.0633, -0.3297,  ...,  0.0461,  0.0650,  0.0792]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0409, device='cuda:0'), logits=tensor([[-1.5849,  1.5911]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  32%|███▏      | 38/120 [00:05<00:13,  5.91batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.2485, -0.5790, -0.7752,  ..., -0.0923, -0.1005, -0.0999]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0088, device='cuda:0'), logits=tensor([[-2.3370,  2.3866]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  32%|███▎      | 39/120 [00:05<00:14,  5.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.0520, -0.0811, -0.0611,  ...,  0.0369,  0.0653,  0.0586]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(5.6518, device='cuda:0'), logits=tensor([[ 2.7552, -2.8931]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.1862, -0.2546, -0.1799,  ...,  0.1421,  0.2352,  0.2893]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  34%|███▍      | 41/120 [00:05<00:13,  5.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0164, device='cuda:0'), logits=tensor([[-2.0319,  2.0721]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.8202, 1.2955, 1.1225,  ..., 0.8307, 0.8599, 0.8894]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0013, device='cuda:0'), logits=tensor([[-3.3060,  3.3504]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  35%|███▌      | 42/120 [00:05<00:12,  6.16batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[0.0449, 0.0891, 0.0521,  ..., 1.6147, 1.5726, 1.5116]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0017, device='cuda:0'), logits=tensor([[-3.1618,  3.2066]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0723, 0.1314, 0.1102,  ..., 0.3660, 0.3418, 0.3220]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  37%|███▋      | 44/120 [00:05<00:11,  6.69batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0007, device='cuda:0'), logits=tensor([[-3.6025,  3.6591]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.2807, -0.4568, -0.3914,  ..., -0.8822, -1.0587, -1.1326]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0009, device='cuda:0'), logits=tensor([[-3.4587,  3.5203]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.1522, 0.2561, 0.2258,  ..., 0.2291, 0.2204, 0.2213]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  39%|███▉      | 47/120 [00:06<00:09,  8.09batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0013, device='cuda:0'), logits=tensor([[-3.2964,  3.3388]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 1.2725e-03,  1.2739e-03,  1.2766e-03,  ...,  1.3685e-03,\n",
      "          6.6244e-05, -5.8765e-04]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0015, device='cuda:0'), logits=tensor([[ 3.2054, -3.2997]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.2679, 0.2515, 0.2339,  ..., 0.7261, 0.4050, 0.8223]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0025, device='cuda:0'), logits=tensor([[ 2.9510, -3.0434]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  40%|████      | 48/120 [00:06<00:08,  8.50batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.0200, -0.0262, -0.0280,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0016, device='cuda:0'), logits=tensor([[ 3.1633, -3.2491]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.3443, -0.5540, -0.4199,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  42%|████▏     | 50/120 [00:06<00:08,  8.09batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.8351, device='cuda:0'), logits=tensor([[-0.1360,  0.1303]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.1693, 0.2805, 0.2403,  ..., 0.4438, 0.4428, 0.4404]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(4.3970, device='cuda:0'), logits=tensor([[-2.1649,  2.2197]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.2964, -0.5448, -0.5291,  ...,  0.2162,  0.2156,  0.2202]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  43%|████▎     | 52/120 [00:06<00:09,  7.35batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(4.0138, device='cuda:0'), logits=tensor([[-1.9618,  2.0337]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-1.2626e-03, -5.5444e-03, -3.3749e-03,  ...,  1.5447e+00,\n",
      "          1.3156e+00,  1.0198e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(6.3242, device='cuda:0'), logits=tensor([[ 3.0843, -3.2381]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  44%|████▍     | 53/120 [00:07<00:09,  7.23batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.0560, -0.0928, -0.0790,  ..., -0.3116,  0.0497,  0.4007]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.0860, device='cuda:0'), logits=tensor([[ 3.4699, -3.6152]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0501, -0.0784, -0.0620,  ...,  1.0306,  1.0188,  1.0133]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  46%|████▌     | 55/120 [00:07<00:08,  7.46batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(6.9351, device='cuda:0'), logits=tensor([[ 3.3958, -3.5383]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0098, -0.0105, -0.0117,  ..., -0.1006, -0.0418, -0.2810]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0038, device='cuda:0'), logits=tensor([[-2.7685,  2.7947]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0603,  0.0628,  0.1015,  ..., -0.9343, -0.8967, -0.8739]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  48%|████▊     | 57/120 [00:07<00:07,  8.32batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0088, device='cuda:0'), logits=tensor([[-2.3636,  2.3659]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.7550,  1.8831,  1.6952,  ..., -1.8670, -2.1029, -1.7980]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0008, device='cuda:0'), logits=tensor([[-3.5264,  3.5983]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0210,  0.0087, -0.0064,  ..., -0.0068, -0.0515, -0.0277]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  49%|████▉     | 59/120 [00:07<00:06,  8.91batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0'), logits=tensor([[ 3.6675, -3.7953]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0017,  0.0021,  0.0016,  ...,  0.0018, -0.0009,  0.0002]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0'), logits=tensor([[ 3.6347, -3.7605]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0081, -0.0067, -0.0055,  ...,  0.5962,  0.7814,  0.9347]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  51%|█████     | 61/120 [00:08<00:07,  7.70batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0007, device='cuda:0'), logits=tensor([[ 3.5911, -3.7230]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.1296, 0.0218, 0.0269,  ..., 0.0028, 0.0273, 0.0144]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0007, device='cuda:0'), logits=tensor([[ 3.5950, -3.7240]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  52%|█████▏    | 62/120 [00:08<00:07,  7.46batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[ 0.0234, -0.1625,  0.0126,  ...,  0.2976,  0.1570,  0.3428]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0'), logits=tensor([[ 3.6442, -3.7696]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0047, -0.0704, -0.1126,  ...,  0.0194,  0.0357,  0.0199]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  53%|█████▎    | 64/120 [00:08<00:07,  7.15batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0007, device='cuda:0'), logits=tensor([[ 3.6034, -3.7177]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0103, -0.0184, -0.0146,  ...,  1.0376,  0.3517, -0.3808]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0019, device='cuda:0'), logits=tensor([[ 3.0823, -3.1643]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0007, -0.0094, -0.0111,  ...,  0.0514,  0.0468,  0.0318]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  55%|█████▌    | 66/120 [00:08<00:07,  7.19batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0015, device='cuda:0'), logits=tensor([[ 3.1875, -3.2944]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0009, -0.0009, -0.0009,  ...,  0.0267,  0.0283,  0.0289]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0016, device='cuda:0'), logits=tensor([[ 3.1599, -3.2654]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  56%|█████▌    | 67/120 [00:08<00:07,  7.19batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[ 0.0090,  0.0172,  0.0128,  ..., -1.5053, -1.3477, -1.0525]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0016, device='cuda:0'), logits=tensor([[ 3.1565, -3.2957]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 2.7359e-03,  2.8632e-03, -1.2583e-03,  ...,  2.4827e+00,\n",
      "          2.1364e+00,  1.7584e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  57%|█████▊    | 69/120 [00:09<00:06,  7.55batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0037, device='cuda:0'), logits=tensor([[ 2.7267, -2.8592]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 9.2216e-05, -1.3379e-03, -3.2872e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0020, device='cuda:0'), logits=tensor([[ 3.0394, -3.1724]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0111,  0.0112,  0.0122,  ...,  0.6320, -0.0534, -0.7132]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  60%|██████    | 72/120 [00:09<00:05,  8.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.1853, device='cuda:0'), logits=tensor([[ 0.7880, -0.8040]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.6791, -0.6670, -0.6468,  ..., -0.0010, -0.0008, -0.0008]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0048, device='cuda:0'), logits=tensor([[ 2.6348, -2.6984]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.7102, 0.6221, 0.5255,  ..., 0.0000, 0.0000, 0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0040, device='cuda:0'), logits=tensor([[ 2.7193, -2.7961]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  61%|██████    | 73/120 [00:09<00:05,  8.33batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[ 0.3029,  0.5316,  0.5066,  ..., -1.9359, -2.2572, -2.3435]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(6.4816, device='cuda:0'), logits=tensor([[-3.1932,  3.2868]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.2010, -0.3609, -0.3345,  ..., -0.8399, -1.0981, -1.2374]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  62%|██████▎   | 75/120 [00:09<00:05,  8.05batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(6.2176, device='cuda:0'), logits=tensor([[-3.0638,  3.1518]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.1476, -0.4490, -0.5916,  ..., -0.0751, -0.0761, -0.0733]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(5.9417, device='cuda:0'), logits=tensor([[-2.9357,  3.0033]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0136, -0.0212, -0.0254,  ...,  2.0888,  2.3775,  2.4537]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  65%|██████▌   | 78/120 [00:10<00:04,  8.90batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(7.3249, device='cuda:0'), logits=tensor([[-3.6215,  3.7027]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 1.0353e-03,  1.8206e-04, -9.0985e-04,  ...,  9.3735e-01,\n",
      "          8.1407e-01,  9.2231e-01]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.2423, device='cuda:0'), logits=tensor([[-3.5781,  3.6635]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 9.9931e-04,  7.1098e-04,  8.0632e-04,  ..., -1.3857e+00,\n",
      "         -1.3989e+00, -1.3779e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.2589, device='cuda:0'), logits=tensor([[-3.5885,  3.6697]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  66%|██████▌   | 79/120 [00:10<00:04,  9.00batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.0009,  0.0403,  0.0770,  ...,  0.0017,  0.0017,  0.0017]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(6.6740, device='cuda:0'), logits=tensor([[-3.2956,  3.3771]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0012, 0.0012, 0.0012,  ..., 0.0000, 0.0000, 0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  68%|██████▊   | 81/120 [00:10<00:04,  9.27batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(2.4187, device='cuda:0'), logits=tensor([[-1.1832,  1.1423]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[1.1758e-04, 5.0132e-04, 9.0807e-05,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(2.8689, device='cuda:0'), logits=tensor([[-1.4127,  1.3978]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0211, -0.0230, -0.0052,  ...,  1.8052,  1.8129,  1.7968]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  69%|██████▉   | 83/120 [00:10<00:04,  8.17batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(3.8995, device='cuda:0'), logits=tensor([[-1.9285,  1.9505]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0559, -0.0772, -0.0537,  ..., -2.4950, -2.8199, -3.1213]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.2064, device='cuda:0'), logits=tensor([[ 0.7176, -0.7556]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0993, -0.1520, -0.1090,  ...,  0.1502,  0.1253,  0.1023]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  71%|███████   | 85/120 [00:11<00:04,  7.93batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.2817, device='cuda:0'), logits=tensor([[ 0.5435, -0.5794]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0136, 0.0254, 0.0176,  ..., 3.0294, 3.1392, 3.2338]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.1707, device='cuda:0'), logits=tensor([[-0.8124,  0.8688]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.1307,  0.2140,  0.1868,  ..., -0.0910, -0.0855, -0.0821]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  72%|███████▎  | 87/120 [00:11<00:04,  7.92batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(3.6974, device='cuda:0'), logits=tensor([[ 1.8023, -1.8701]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.2367, 0.3974, 0.3531,  ..., 0.0900, 0.0884, 0.0880]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.1025, device='cuda:0'), logits=tensor([[-1.0876,  1.1389]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.1868,  0.2446,  0.2756,  ..., -1.1397, -0.9474, -0.6226]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  74%|███████▍  | 89/120 [00:11<00:03,  8.51batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0545, device='cuda:0'), logits=tensor([[-1.4311,  1.4501]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[3.4235e+00, 7.3567e+00, 9.0863e+00,  ..., 1.6953e-03, 1.2603e-03,\n",
      "         1.2054e-03]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0463, device='cuda:0'), logits=tensor([[-1.5271,  1.5215]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-1.8090, -1.6793, -1.6429,  ..., -0.0284, -0.0287, -0.0253]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  76%|███████▌  | 91/120 [00:11<00:03,  8.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=tensor(0.0387, device='cuda:0'), logits=tensor([[-1.6139,  1.6194]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.3938, -0.4581, -0.5134,  ...,  0.0039,  0.0036,  0.0037]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.1168, device='cuda:0'), logits=tensor([[-3.5140,  3.6019]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0107, 0.0337, 0.0546,  ..., 0.0008, 0.0009, 0.0007]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  78%|███████▊  | 93/120 [00:11<00:03,  8.89batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(6.3519, device='cuda:0'), logits=tensor([[-3.1315,  3.2187]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0074, 0.0099, 0.0121,  ..., 0.0026, 0.0027, 0.0026]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(4.4935, device='cuda:0'), logits=tensor([[-2.2159,  2.2664]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0038, -0.0009,  0.0012,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  79%|███████▉  | 95/120 [00:12<00:03,  8.23batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0802, device='cuda:0'), logits=tensor([[-1.2579,  1.2251]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0878, -0.1335, -0.1047,  ..., -0.0152, -0.0161, -0.0130]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.1503, device='cuda:0'), logits=tensor([[ 3.5069, -3.6426]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0005, 0.0011, 0.0010,  ..., 0.0000, 0.0000, 0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  81%|████████  | 97/120 [00:12<00:02,  8.54batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(4.3558, device='cuda:0'), logits=tensor([[ 2.1358, -2.2070]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.9240,  0.4079,  0.1708,  ..., -1.1280, -1.6013, -2.0224]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0007, device='cuda:0'), logits=tensor([[-3.5600,  3.6460]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.5084,  0.4426,  0.3869,  ..., -1.5969, -2.0671, -1.5654]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  82%|████████▎ | 99/120 [00:12<00:02,  8.93batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0018, device='cuda:0'), logits=tensor([[-3.1238,  3.1941]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0004,  0.0010,  0.0005,  ...,  0.0000,  0.0000,  0.0000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0013, device='cuda:0'), logits=tensor([[-3.2841,  3.3645]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0032, 0.0031, 0.0027,  ..., 0.0015, 0.0014, 0.0010]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  84%|████████▍ | 101/120 [00:12<00:02,  9.04batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(6.9165, device='cuda:0'), logits=tensor([[ 3.4009, -3.5146]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0034, 0.0036, 0.0033,  ..., 0.0008, 0.0008, 0.0009]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.1201, device='cuda:0'), logits=tensor([[ 3.5006, -3.6186]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.0049, 0.0051, 0.0054,  ..., 0.0006, 0.0004, 0.0011]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  86%|████████▌ | 103/120 [00:13<00:01,  9.03batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(7.2778, device='cuda:0'), logits=tensor([[ 3.5804, -3.6967]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0002, -0.0006, -0.0004,  ..., -0.0143, -0.0432, -0.0446]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.2626, device='cuda:0'), logits=tensor([[-3.6005,  3.6614]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 8.7985e-04,  7.1835e-04, -3.8982e-04,  ...,  2.5189e-01,\n",
      "          1.3204e+00,  2.0586e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  88%|████████▊ | 105/120 [00:13<00:01,  9.19batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(7.3034, device='cuda:0'), logits=tensor([[-3.6168,  3.6860]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0006, -0.0008, -0.0005,  ..., -0.0078, -0.0052, -0.0020]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(7.3103, device='cuda:0'), logits=tensor([[-3.6178,  3.6919]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0546, -0.1873, -0.0202,  ...,  0.0790,  0.0522,  0.2618]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  89%|████████▉ | 107/120 [00:13<00:01,  8.46batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0210, device='cuda:0'), logits=tensor([[ 1.8933, -1.9599]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.2684,  0.4375,  0.3824,  ..., -0.3363,  0.2331,  0.1117]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.0032, device='cuda:0'), logits=tensor([[ 2.8075, -2.9239]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[0.1154, 0.1844, 0.1681,  ..., 0.1208, 0.1356, 0.1465]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  91%|█████████ | 109/120 [00:13<00:01,  8.62batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(0.0038, device='cuda:0'), logits=tensor([[ 2.7211, -2.8398]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.1382,  0.0662,  0.0445,  ..., -0.7886, -1.0872, -0.8828]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(6.4870, device='cuda:0'), logits=tensor([[-3.2138,  3.2718]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0148,  0.0789,  0.0643,  ...,  0.0015, -0.0064, -0.0052]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  92%|█████████▎| 111/120 [00:14<00:01,  8.99batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(6.9617, device='cuda:0'), logits=tensor([[-3.4350,  3.5258]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[5.6853e+00, 6.1956e+00, 6.9170e+00,  ..., 3.1556e-04, 4.7733e-05,\n",
      "         8.5993e-04]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(6.6404, device='cuda:0'), logits=tensor([[-3.2825,  3.3565]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-3.8899e+00, -2.6246e+00, -1.1406e+00,  ..., -1.7397e-03,\n",
      "         -2.2103e-03, -1.5764e-03]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  94%|█████████▍| 113/120 [00:14<00:00,  9.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(2.0110, device='cuda:0'), logits=tensor([[ 0.9301, -0.9372]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.0886, -1.1655,  0.0092,  ..., -0.0103, -0.0080, -0.0101]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(3.5568, device='cuda:0'), logits=tensor([[ 1.7191, -1.8087]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.4283, -0.4671, -0.4308,  ...,  0.3333,  0.2024,  0.2881]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  96%|█████████▌| 115/120 [00:14<00:00,  9.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(3.2693, device='cuda:0'), logits=tensor([[ 1.5851, -1.6454]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[ 0.1921,  0.1898,  0.1084,  ..., -0.1120, -0.1641, -0.2204]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(0.2451, device='cuda:0'), logits=tensor([[-0.6778,  0.6031]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.3316,  0.1802,  0.6821,  ..., -0.0325,  0.1482,  0.2199]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  98%|█████████▊| 117/120 [00:14<00:00,  9.21batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(2.9035, device='cuda:0'), logits=tensor([[ 1.3762, -1.4708]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n",
      "data: {'input_values': tensor([[-1.2905, -1.0987, -0.8549,  ..., -0.0141,  0.0134,  0.0195]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([1])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(4.4987, device='cuda:0'), logits=tensor([[ 2.1841, -2.3035]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  98%|█████████▊| 118/120 [00:14<00:00,  7.46batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.0092, -0.0192, -0.0199,  ...,  0.2475,  0.3517,  0.4059]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(3.9731, device='cuda:0'), logits=tensor([[-1.9469,  2.0072]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  99%|█████████▉| 119/120 [00:15<00:00,  6.26batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'input_values': tensor([[-0.0404, -0.0658, -0.0566,  ..., -1.7107, -2.0841, -2.3900]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n",
      "outputs: SequenceClassifierOutput(loss=tensor(5.3932, device='cuda:0'), logits=tensor([[-2.6472,  2.7414]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "data: {'input_values': tensor([[-0.0047, -0.0093, -0.0096,  ...,  0.0492,  0.0525,  0.0551]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n",
      "labels: tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 120/120 [00:15<00:00,  7.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: SequenceClassifierOutput(loss=tensor(6.7453, device='cuda:0'), logits=tensor([[-3.3275,  3.4166]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "predicted: tensor([1], device='cuda:0')\n",
      "Testing Loss: 2.7364, Testing Results: Acc 48.33%,       Sensitivity 55.56%, Specificity 40.35%,         F1 53.03%, ROC AUC 0.00%,             Precision 50.72%, Recall 55.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming CustomDataset is already defined and data is loaded\n",
    "# dataset = CustomDataset(data, labels)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "#input_size = 10  # Example input size\n",
    "from multiprocessing import process\n",
    "from tkinter import Y\n",
    "from tkinter.filedialog import test\n",
    "from idna import valid_contextj\n",
    "from torch import mode\n",
    "\n",
    "\n",
    "num_classes = 2  # Example number of classes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "model_save_path = './trained models/mci model 85 acc.pth'\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Load accuracy metric\n",
    "test_loss = 0.0\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_dataset_dataloader, unit=\"batch\") as tepoch:\n",
    "        for data, labels in tepoch:\n",
    "            tepoch.set_description(f\"Testing\")\n",
    "            data[\"input_values\"] = data[\"input_values\"][0]\n",
    "            data[\"attention_mask\"] = data[\"attention_mask\"][0]\n",
    "            print('data:', data)\n",
    "            print('labels:', labels)\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_values=data[\"input_values\"], attention_mask=data[\"attention_mask\"], labels=labels)\n",
    "            print('outputs:', outputs)\n",
    "            #loss = criterion(outputs.logits, labels)\n",
    "            loss = outputs.loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            print('predicted:', predicted)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            #accuracy = 100 * correct / total\n",
    "            #tepoch.set_postfix(loss=loss.item())\n",
    "# Compute and print accuracy at the end of the epoch\n",
    "test_loss /= len(test_dataset_dataloader)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Assuming you have y_true (true labels) and y_pred (predicted labels):\n",
    "y_true = true_labels\n",
    "y_pred = predictions\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Sensitivity (Recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# F1-score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# AUC-ROC\n",
    "auc = 0#roc_auc_score(y_true, y_pred_proba[:, 1]) # For binary classification, use probabilities of positive class\n",
    "\n",
    "# Precision and Recall\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "test_results = {}\n",
    "test_results[\"accuracy\"] = accuracy\n",
    "test_results[\"sensitivity\"] = sensitivity\n",
    "test_results[\"specificity\"] = specificity\n",
    "test_results[\"f1\"] = f1\n",
    "test_results[\"roc_auc\"] = auc\n",
    "test_results[\"precision\"] = precision\n",
    "test_results[\"recall\"] = recall\n",
    "\n",
    "print(f\"Testing Loss: {test_loss:.4f}, Testing Results: Acc {test_results['accuracy'] * 100:.2f}%, \\\n",
    "      Sensitivity {test_results['sensitivity'] * 100:.2f}%, Specificity {test_results['specificity'] * 100:.2f}%, \\\n",
    "        F1 {test_results['f1'] * 100:.2f}%, ROC AUC {test_results['roc_auc'] * 100:.2f}%, \\\n",
    "            Precision {test_results['precision'] * 100:.2f}%, Recall {test_results['recall'] * 100:.2f}%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "y_pred: [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print('y_true:', y_true)\n",
    "print('y_pred:', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list, label=\"Training Loss\")\n",
    "plt.plot(val_loss_list, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./trained models/mci model 85 acc.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = './trained models/mci model 85 acc.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
